{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import _jsonnet\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/gap-text2sql/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from seq2struct.commands.infer import Inferer\n",
    "from seq2struct.datasets.spider import SpiderItem\n",
    "from seq2struct.utils import registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_config = json.loads(\n",
    "    _jsonnet.evaluate_file(\n",
    "        \"experiments/spider-configs/gap-run.jsonnet\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config_path = exp_config[\"model_config\"]\n",
    "model_config_args = exp_config.get(\"model_config_args\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_config = json.loads(\n",
    "    _jsonnet.evaluate_file(\n",
    "        model_config_path, \n",
    "        tla_codes={'args': json.dumps(model_config_args)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_config[\"model\"][\"encoder_preproc\"][\"db_path\"] = \"data/sqlite_files/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING <class 'seq2struct.models.enc_dec.EncDecModel.Preproc'>: superfluous {'name': 'EncDec'}\n"
     ]
    }
   ],
   "source": [
    "inferer = Inferer(infer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = exp_config[\"logdir\"] + \"/bs=12,lr=1.0e-04,bert_lr=1.0e-05,end_lr=0e0,att=1\"\n",
    "checkpoint_step = exp_config[\"eval_steps\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING <class 'seq2struct.models.enc_dec.EncDecModel'>: superfluous {'decoder_preproc': {'grammar': {'clause_order': None, 'end_with_from': True, 'factorize_sketch': 2, 'include_literals': False, 'infer_from_conditions': True, 'name': 'spider', 'output_from': True, 'use_table_pointer': True}, 'save_path': 'data/spider-bart/nl2code-1115,output_from=true,fs=2,emb=bart,cvlink', 'use_seq_elem_rules': True}, 'encoder_preproc': {'bart_version': 'facebook/bart-large', 'compute_cv_link': True, 'compute_sc_link': True, 'db_path': 'data/sqlite_files/', 'fix_issue_16_primary_keys': True, 'include_table_name_in_column': False, 'save_path': 'data/spider-bart/nl2code-1115,output_from=true,fs=2,emb=bart,cvlink'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0370,  0.1117,  0.1829,  ...,  0.2054,  0.0578, -0.0750],\n",
      "        [ 0.0055, -0.0049, -0.0069,  ..., -0.0030,  0.0038,  0.0087],\n",
      "        [-0.0448,  0.4604, -0.0604,  ...,  0.1073,  0.0310,  0.0477],\n",
      "        ...,\n",
      "        [-0.0138,  0.0278, -0.0467,  ...,  0.0455, -0.0265,  0.0125],\n",
      "        [-0.0043,  0.0153, -0.0567,  ...,  0.0496,  0.0108, -0.0099],\n",
      "        [ 0.0053,  0.0324, -0.0179,  ..., -0.0085,  0.0223, -0.0020]],\n",
      "       requires_grad=True)\n",
      "Updated the model with ./pretrained_checkpoint/pytorch_model.bin\n",
      "Parameter containing:\n",
      "tensor([[-3.8313e-02,  1.2050e-01,  1.7760e-01,  ...,  1.9729e-01,\n",
      "          5.9443e-02, -6.9929e-02],\n",
      "        [ 4.5650e-03, -2.3032e-03, -8.4326e-03,  ..., -3.5686e-03,\n",
      "          4.7121e-03,  8.4110e-03],\n",
      "        [-4.5997e-02,  4.6710e-01, -6.5000e-02,  ...,  1.0271e-01,\n",
      "          2.5631e-02,  4.7501e-02],\n",
      "        ...,\n",
      "        [ 1.5723e-02, -2.5663e-02,  5.2457e-03,  ..., -1.6183e-02,\n",
      "          1.9788e-02, -6.2702e-03],\n",
      "        [-3.3508e-03,  9.6615e-04, -5.9775e-03,  ..., -1.3251e-02,\n",
      "         -6.4723e-03, -1.5651e-02],\n",
      "        [ 4.6797e-05, -1.1256e-02, -2.4231e-02,  ..., -4.9586e-03,\n",
      "         -1.1959e-02, -1.7317e-02]], requires_grad=True)\n",
      "Loading model from logdir/bart_run_1/bs=12,lr=1.0e-04,bert_lr=1.0e-05,end_lr=0e0,att=1/model_checkpoint-00041000\n"
     ]
    }
   ],
   "source": [
    "model = inferer.load_model(model_dir, checkpoint_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seq2struct.datasets.spider_lib.preprocess.get_tables import dump_db_json_schema\n",
    "from seq2struct.datasets.spider import load_tables_from_schema_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_id = \"security_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_schema = dump_db_json_schema(\"data/sqlite_files/{db_id}/{db_id}.sqlite\".format(db_id=db_id), db_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seq2struct.utils.api_utils import refine_schema_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'db_id': 'music_1',\n",
       " 'table_names_original': ['genre', 'artist', 'files', 'song'],\n",
       " 'table_names': ['genre', 'artist', 'files', 'song'],\n",
       " 'column_names_original': [(-1, '*'),\n",
       "  (0, 'g_name'),\n",
       "  (0, 'rating'),\n",
       "  (0, 'most_popular_in'),\n",
       "  (1, 'artist_name'),\n",
       "  (1, 'country'),\n",
       "  (1, 'gender'),\n",
       "  (1, 'preferred_genre'),\n",
       "  (2, 'f_id'),\n",
       "  (2, 'artist_name'),\n",
       "  (2, 'file_size'),\n",
       "  (2, 'duration'),\n",
       "  (2, 'formats'),\n",
       "  (3, 'song_name'),\n",
       "  (3, 'artist_name'),\n",
       "  (3, 'country'),\n",
       "  (3, 'f_id'),\n",
       "  (3, 'genre_is'),\n",
       "  (3, 'rating'),\n",
       "  (3, 'languages'),\n",
       "  (3, 'releasedate'),\n",
       "  (3, 'resolution')],\n",
       " 'column_names': [(-1, '*'),\n",
       "  (0, 'g name'),\n",
       "  (0, 'rating'),\n",
       "  (0, 'most popular in'),\n",
       "  (1, 'artist name'),\n",
       "  (1, 'country'),\n",
       "  (1, 'gender'),\n",
       "  (1, 'preferred genre'),\n",
       "  (2, 'f id'),\n",
       "  (2, 'artist name'),\n",
       "  (2, 'file size'),\n",
       "  (2, 'duration'),\n",
       "  (2, 'formats'),\n",
       "  (3, 'song name'),\n",
       "  (3, 'artist name'),\n",
       "  (3, 'country'),\n",
       "  (3, 'f id'),\n",
       "  (3, 'genre is'),\n",
       "  (3, 'rating'),\n",
       "  (3, 'languages'),\n",
       "  (3, 'releasedate'),\n",
       "  (3, 'resolution')],\n",
       " 'column_types': ['text',\n",
       "  'text',\n",
       "  'text',\n",
       "  'text',\n",
       "  'text',\n",
       "  'text',\n",
       "  'text',\n",
       "  'text',\n",
       "  'number',\n",
       "  'text',\n",
       "  'text',\n",
       "  'text',\n",
       "  'text',\n",
       "  'text',\n",
       "  'text',\n",
       "  'text',\n",
       "  'number',\n",
       "  'text',\n",
       "  'number',\n",
       "  'text',\n",
       "  'time',\n",
       "  'number'],\n",
       " 'primary_keys': [1, 4, 8, 13],\n",
       " 'foreign_keys': [[7, 1], [9, 4], [17, 1], [16, 8], [14, 4]]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema, eval_foreign_key_maps = load_tables_from_schema_dict(my_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['music_1'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = registry.construct('dataset_infer', {\n",
    "   \"name\": \"spider\", \"schemas\": schema, \"eval_foreign_key_maps\": eval_foreign_key_maps, \n",
    "    \"db_path\": \"data/sqlite_files/\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, schema in dataset.schemas.items():\n",
    "    model.preproc.enc_preproc._preprocess_schema(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "spider_schema = dataset.schemas[db_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(question):\n",
    "    data_item = SpiderItem(\n",
    "            text=None,  # intentionally None -- should be ignored when the tokenizer is set correctly\n",
    "            code=None,\n",
    "            schema=spider_schema,\n",
    "            orig_schema=spider_schema.orig,\n",
    "            orig={\"question\": question}\n",
    "        )\n",
    "    model.preproc.clear_items()\n",
    "    enc_input = model.preproc.enc_preproc.preprocess_item(data_item, None)\n",
    "    preproc_data = enc_input, None\n",
    "    with torch.no_grad():\n",
    "        output = inferer._infer_one(model, data_item, preproc_data, beam_size=1, use_heuristic=True)\n",
    "    return output[0][\"inferred_code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/gap-text2sql/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT Avg(song.rating), Avg(song.resolution) FROM song WHERE song.languages = 'terminal'\n"
     ]
    }
   ],
   "source": [
    "code = infer(\"What type of device operating systems are used by the customer?\")\n",
    "print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/gap-text2sql/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT Avg(song.rating), Avg(song.resolution) FROM song WHERE song.languages = 'terminal'\n"
     ]
    }
   ],
   "source": [
    "code = infer(\"Can you provide a breakdown of the different payment types used by customers in the database, and how many customers used each payment type in the last month?\")\n",
    "print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/gap-text2sql/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT Avg(song.rating), Avg(song.resolution) FROM song WHERE song.languages = 'terminal'\n"
     ]
    }
   ],
   "source": [
    "code = infer(\"What is the average credit risk score based on age group?\")\n",
    "print(code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
